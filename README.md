# ğŸ“š LangChain RAG Chatbot with ChromaDB and Flask

A lightweight **Retrieval-Augmented Generation (RAG)** chatbot that combines the power of local embeddings, efficient vector search, and an interactive chat UI.

---

## âœ¨ Overview

This project is a fully functional chatbot built with:

- ğŸ§  **LangChain** â€“ For chaining LLMs with tools like retrievers and memory
- ğŸ“¦ **ChromaDB** â€“ As the vector store for fast similarity search
- ğŸ’¬ **HuggingFace Embeddings** â€“ Local model (`all-MiniLM-L6-v2`) for privacy and no external API dependency
- ğŸŒ **Flask** â€“ Web interface with a responsive, minimalistic chat-style UI
- âš™ï¸ **Optional** â€“ Support for OpenAI API for LLM responses (can be replaced)

---

## ğŸ–¼ï¸ Demo Screenshot

![Chatbot Screenshot](https://github.com/user-attachments/assets/c4e47f0b-ab58-4ba4-aaaf-d8da1a8af285)

---

## ğŸš€ Features

- âœ… Local embedding using HuggingFace (`sentence-transformers`)
- ğŸ§  RAG pipeline with document retrieval and response generation
- ğŸ’¬ Chat UI with session-based conversation memory
- ğŸ“± Clean, mobile-friendly frontend using Flask + HTML/CSS
- ğŸ”„ Easy to extend with new documents, embeddings, or LLMs

---

## ğŸ“¦ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/arryc2021/Metadata-science-platform.git
cd Metadata-science-platform
2. Install Dependencies
If requirements.txt is available:

bash
Copy
Edit
pip install -r requirements.txt
Or manually install the key dependencies:

bash
Copy
Edit
pip install flask flask-session langchain chromadb sentence-transformers openai
ğŸ§  (Optional) Set OpenAI API Key
If you'd like to use OpenAI's LLMs instead of local ones:
export OPENAI_API_KEY=your-key-here
# On Windows:
# set OPENAI_API_KEY=your-key
ğŸ“„ Prepare Your Data
Add your knowledge base as plain text in a file named data.txt.

Example:
# Download or create your dataset
wget https://example.com/data.txt
Make sure the file is named data.txt and placed in the root directory.

ğŸ”„ Ingest Data into ChromaDB
Run the data ingestion script:
python ingest.py
This will:

Load the data.txt file

Split the content into manageable chunks

Generate local embeddings using a HuggingFace model

Store embeddings in chroma_db/

ğŸ’¬ Run the Flask App
To start the chatbot:
python app.py
Then open your browser and go to:

http://localhost:5000
ğŸ§ª Example Questions
Once the chatbot is running, try asking:

"What is leadership?"

"Summarize chapter 4."

"Give me a quote about leadership."

ğŸ—‚ï¸ Project Structure
â”œâ”€â”€ app.py              # Flask app with chat session
â”œâ”€â”€ agent.py            # RAG logic: retrieval and LLM response
â”œâ”€â”€ ingest.py           # Script for document ingestion and embedding
â”œâ”€â”€ data.txt            # Plain text knowledge base
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html      # Frontend chat UI
â”œâ”€â”€ chroma_db/          # Persisted vector database
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md           # Project documentation
ğŸ¯ Project Objective
The goal of this project is to demonstrate how to build a fully local, customizable RAG chatbot using modern open-source tools. Itâ€™s ideal for:

Educational purposes in NLP/LLM pipelines

Building Q&A bots from custom knowledge sources

Rapid prototyping for AI assistants without cloud dependency

ğŸ¤ Contributing
Pull requests, issues, and feedback are welcome!

If you'd like to contribute:

Fork the repo

Create a new branch (git checkout -b feature-name)

Commit your changes

Push to your fork

Open a pull request
ğŸ“„ License
This project is licensed under the MIT License â€“ see the LICENSE file for details.


Let me know if you'd like to also include:

- Deployment instructions (Docker, Heroku, etc.)
- Local vs OpenAI toggle instructions
- Extended UI customization options
- Test cases or CI setup

I can help add those as well.


